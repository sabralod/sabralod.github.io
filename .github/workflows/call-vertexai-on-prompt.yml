name: 'call-vertexai-on-prompt'

on:
  push:
    paths:
      - '.github/workflows/call-vertexai-on-prompt.yml'
      - 'prompts/**'
  workflow_dispatch:

jobs:
  process-prompts:
    runs-on: ['self-hosted', 'linux']

    env:
      VERTEXAI_CREDENTIALS: ${{ secrets.VERTEXAI_CREDENTIALS }}

    steps:
      - uses: 'actions/checkout@v4'

      - name: read-prompt-file
        id: read_prompt
        shell: bash
        run: |
          echo "method=$(yq '.method' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "modelName=$(yq '.modelName' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT

          EOF=$(dd if=/dev/urandom bs=15 count=1 status=none | base64)
          echo "history<<$EOF" >> $GITHUB_OUTPUT
          echo "$(yq '.history' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "$EOF" >> $GITHUB_OUTPUT
          
          echo "message=$(yq '.message' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "temperature=$(yq '.temperature' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "topp=$(yq '.topp' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "topk=$(yq '.topk' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "candidateCount=$(yq '.candidateCount' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "maxOutputTokens=$(yq '.maxOutputTokens' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT
          echo "stopSequences=$(yq '.stopSequences' prompts/prompt1.yml -o=json)" >> $GITHUB_OUTPUT

      - name: use-yaml-file
        run: |
          echo method: ${{ steps.read_prompt.outputs['method'] }}
          echo modelName: ${{ steps.read_prompt.outputs['modelName'] }}
          echo history: ${{ fromJSON(steps.read_prompt.outputs['history']) }}
          echo message: ${{ steps.read_prompt.outputs['message'] }}
          echo temperature: ${{ steps.read_prompt.outputs['temperature'] }}
          echo topp: ${{ steps.read_prompt.outputs['topp'] }}
          echo topk: ${{ steps.read_prompt.outputs['topk'] }}
          echo candidateCount: ${{ steps.read_prompt.outputs['candidateCount'] }}
          echo maxOutputTokens: ${{ steps.read_prompt.outputs['maxOutputTokens'] }}
          echo stopSequences: ${{ steps.read_prompt.outputs['stopSequences'] }}

      - name: Run vertexai-action
        id: run-vertexai-action
        uses: docker://ghcr.io/sabralod/vertexai-action:go-action
        with:
          projectId: 'test-project-1-420005'
          region: 'us-central1'
          credentialsFile: ''
          credentials: "${{ env.VERTEXAI_CREDENTIALS }}"
          method: ${{ steps.read_prompt.outputs['method'] }}
          modelName: ${{ steps.read_prompt.outputs['modelName'] }}
          message: ${{ steps.read_prompt.outputs['message'] }}
          temperature: ${{ steps.read_prompt.outputs['temperature'] }}
          topp: ${{ steps.read_prompt.outputs['topp'] }}
          topk: ${{ steps.read_prompt.outputs['topk'] }}
          candidateCount: ${{ steps.read_prompt.outputs['candidateCount'] }}
          maxOutputTokens: ${{ steps.read_prompt.outputs['maxOutputTokens'] }}
          stopSequences: ${{ steps.read_prompt.outputs['stopSequences'] }}
          history: "${{ steps.read_prompt.outputs['history'] }}"
